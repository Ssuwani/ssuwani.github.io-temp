---
title: '[MLOps] Vertex AIì—ì„œ ëª¨ë¸ ë°°í¬í•˜ê¸° (MNIST)'
date: '2021-11-01'
category: 'blog'
description: ''
emoji: 'ğŸƒ'

---

> ê°„ë‹¨í•œ ì½”ë“œë¡œ Vertex AIì—ì„œ ëª¨ë¸ í•™ìŠµ ë° ë°°í¬í•˜ëŠ” ê³¼ì •ì„ ë‹¤ë£¬ë‹¤.

MNIST ë°ì´í„°ëŠ” ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ê³¼ì •ì„ ê°„ë‹¨í•˜ê²Œ `load_data`ë¡œ í•  ìˆ˜ ìˆê¸° ë•Œë¬¸ì— ì•„ë˜ì™€ ê°™ì´ ê°„ë‹¨íˆ 2ê°œì˜ ì»´í¬ë„ŒíŠ¸ë¡œ êµ¬ì„±í•  ìˆ˜ ìˆë‹¤.

- Load data & Training
- Deploy with endpoint

ì•„ë˜ì˜ ê³¼ì •ì„ ë”°ë¼ì˜¤ë©´ ë‹¤ìŒê³¼ ê°™ì€ íŒŒì´í”„ë¼ì¸ì„ ì„¤ê³„í•  ìˆ˜ ìˆë‹¤.

<img src="simple_pipeline.png" width="50%"/>

## 0. Import Library

Libraryë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ë¶€ë¶„ì´ë‹¤.

```python
import kfp
from kfp import dsl
from kfp.v2 import compiler
from kfp.v2.dsl import (Artifact, Dataset, Input, InputPath, Model, Output,
                        OutputPath, ClassificationMetrics, Metrics, component)

from google.cloud.aiplatform import pipeline_jobs

from datetime import datetime
```





## 1. Load data & Training Component

ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì™€ì„œ ì „ì²˜ë¦¬ í•œ ë’¤ ëª¨ë¸ì„ ì •ì˜í•˜ê³  í•™ìŠµì„ ì§„í–‰í•  ê²ƒì´ë‹¤. ì‚¬ì‹¤ ê°ê°ì˜ ì»´í¬ë„ŒíŠ¸ë¡œ êµ¬í˜„ì„ í•˜ëŠ” ê²ƒì´ ì˜³ì„ì§€ ëª¨ë¥´ê² ë‹¤. ê°„ë‹¨í•˜ê²Œ ë°°í¬ë¥¼ ìœ„í•œ í¬ìŠ¤íŒ…ì´ë‹ˆ í•˜ë‚˜ì˜ ì»´í¬ë„ŒíŠ¸ë¡œ êµ¬ì„±í–ˆë‹¤.

```python
@component(
    packages_to_install=["tensorflow"] # 1
)
def load_data_and_training(
    output_model: Output[Model], # 2
    metrics: Output[Metrics] # 3
):
    import tensorflow as tf
    
    mnist = tf.keras.datasets.mnist # 4
    (train_x, train_y), (test_x, test_y) = mnist.load_data()
    train_x = train_x / 255.0
    test_x = test_x / 255.0
    
    model = tf.keras.Sequential( # 5
        [
            tf.keras.layers.Flatten(input_shape=(28, 28)),
            tf.keras.layers.Dense(128, activation='relu'),
            tf.keras.layers.Dense(10, activation='softmax')
        ]
    )
    model.compile( # 6
        optimizer='adam',
        loss='sparse_categorical_crossentropy',
        metrics=['accuracy']
    )
    model.fit(train_x, train_y, epochs=3) # 7
    loss, acc = model.evaluate(test_x, test_y) # 8
    
    metrics.log_metric("acc", (acc*100.0)) # 9
    metrics.log_metric("loss", loss)
    metrics.log_metric("Model", "LinearModel")
    metrics.log_metric("dataset size", len(train_x))
    
    model.save(output_model.path) # 10

    print(f"Model saved path : {output_model.path}")
    print(f"Model saved uri : {output_model.uri}")
```

ì½”ë“œ ì˜†ì— ì£¼ì„ìœ¼ë¡œ ìˆ«ìë¥¼ í‘œì‹œí•´ë‘ì—ˆë‹¤. ê°„ë‹¨í•˜ê²Œ ì„¤ëª…ì„ ì ì–´ë‘ë ¤ í•œë‹¤.

- 1: `kip.v2.dsl` ì— ì •ì˜ëœ `component`  ë°ì½”ë ˆì´í„°ì´ë‹¤. ì¼ë°˜ í•¨ìˆ˜ë¥¼ íŒŒì´í”„ë¼ì¸ ì»´í¬ë„ŒíŠ¸ë¡œ ë³€ê²½í•´ì¤€ë‹¤. 3ê°œì˜ argumentë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤.
    - `base_image` : ì§€ì •í•´ì£¼ì§€ ì•Šìœ¼ë©´ ê¸°ë³¸ì ìœ¼ë¡œ python:3.7 ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•œë‹¤.
    - `output_component_file` : componentì— ì •ì˜ëœ ë‚´ìš©ì„ `yaml` íŒŒì¼ë¡œ ì‘ì„±í•˜ì—¬ í˜‘ì—…ì„ ìœ„í•´ ì‚¬ìš©í•˜ê±°ë‚˜ ë‹¤ë¥¸ íŒŒì´í”„ë¼ì¸ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤.
    - `packages_to_install`: base_imageì—ì„œ ì¶”ê°€ì ìœ¼ë¡œ íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•  ë•Œ ì‚¬ìš©í•œë‹¤. íŒ¨í‚¤ì§€ ë¦¬ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•´ì£¼ë©´ ëœë‹¤. ë‚˜ì˜ ê²½ìš° python:3.7 ì´ë¯¸ì§€ì— tensorflowë¥¼ ì„¤ì¹˜í–ˆë‹¤.
- 2: Ouputì€ ì»´í¬ë„ŒíŠ¸ì˜ ì¶œë ¥ì„ ì •ì˜í•  ìˆ˜ ìˆë‹¤. í›ˆë ¨í•œ ëª¨ë¸ì„ ì €ì¥í•˜ê¸° ìœ„í•œ ê²½ë¡œë¥¼ Deploy Componentì—ì„œ ì‚¬ìš©í•˜ê¸° ìœ„í•´ ì¶œë ¥í–ˆë‹¤.
- 3: Metricsì€ ìœ„ì™€ê°™ì´ `log_metric` ìœ¼ë¡œ ê°’ì„ ì£¼ë©´ Vertex AI Pipelineì˜ "ì‹¤í–‰ ì¸¡ì •í•­ëª©" ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆì„ ë¿ë§Œ ì•„ë‹ˆë¼ ì—¬ëŸ¬ê°œì˜ íŒŒì´í”„ë¼ì¸ì„ ì„ íƒí•˜ì—¬ Metricsì— ì…ë ¥í•œ ê°’ì„ ê¸°ë°˜ìœ¼ë¡œ ì„œë¡œ ë¹„êµí•  ìˆ˜ ìˆë‹¤.
- 4: MNIST ë°ì´í„°ì…‹ì˜ ë¶ˆëŸ¬ì˜¤ê³  ì „ì²˜ë¦¬ë¥¼ í•˜ëŠ” ê³¼ì •ì´ë‹¤.
- 5: Tensorflowë¡œ ê°„ë‹¨í•œ Linear Modelì„ ì •ì˜í•˜ëŠ” ë¶€ë¶„ì´ë‹¤.
- 6: ëª¨ë¸ í•™ìŠµê³¼ì •ì„ ì •ì˜í•˜ëŠ” compile ë¶€ë¶„ì´ë‹¤.
- 7: ëª¨ë¸ í•™ìŠµ
- 8: ëª¨ë¸ í‰ê°€, ê¸°ë³¸ì ìœ¼ë¡œ lossë¥¼ ë°˜í™˜í•˜ê³  `compile` ì‹œ `metrics` ë¡œ ì§€ì •í–ˆë˜ ì¸¡ì •í•­ëª©ë“¤ì´ ìˆœì„œëŒ€ë¡œ ì¶œë ¥ëœë‹¤.
- 9: 3ë²ˆì—ì„œ ì´ì•¼ê¸°í–ˆë˜ Component mertricì„ ì§€ì •í•˜ëŠ” ë¶€ë¶„ì´ë‹¤. key valueì˜ ìŒìœ¼ë¡œ ê°’ì„ ì¤€ë‹¤.
- 10: ëª¨ë¸ì„ ì €ì¥í•˜ëŠ” ë¶€ë¶„ì´ë‹¤. Outputìœ¼ë¡œ ì§€ì •í–ˆë˜ output_modelì˜ pathì— ëª¨ë¸ì„ ì €ì¥í•œë‹¤



Metricsì˜ `log_metric` ìœ¼ë¡œ ì§€ì •í•œ ë’¤ í•™ìŠµì˜ ê²°ê³¼ëŠ” ë‹¤ìŒê³¼ ê°™ì´ í™•ì¸í•  ìˆ˜ ìˆë‹¤.

<img src="metrics.png" width="50%"/>

CNN ëª¨ë¸ì„ í•˜ë‚˜ ë” ë§Œë“¤ì–´ì„œ ê°„ë‹¨í•˜ê²Œ ë¹„êµí•´ë³´ì•˜ë‹¤. ì°¸ê³ ë¡œë§Œ ë³´ì.

<img src="compare.png" width="1000%"/>

## 2. Deploy with endpoint

ì•ì„œ ì €ì¥í•œ ëª¨ë¸ì„ ì„œë¹™í•˜ëŠ” ë¶€ë¶„ì´ë‹¤. ëª¨ë¸ì„ ë°°í¬í•˜ê³  endpointë¥¼ ìƒì„±í•˜ì—¬ ì—°ê²°í•œë‹¤.

```python
@component(
    packages_to_install=["google-cloud-aiplatform"]
)
def deploy_model(
    model: Input[Model],
    project: str,
    region: str,
    vertex_endpoint: Output[Artifact],
    vertex_model: Output[Model]
):
    from google.cloud import aiplatform

    aiplatform.init(project=project, location=region) # 1

    deployed_model = aiplatform.Model.upload( # 2
        display_name="simple-mnist-pipeline",
        artifact_uri = model.uri,
        serving_container_image_uri="us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-6:latest"
    )
    endpoint = deployed_model.deploy(machine_type="n1-standard-4") # 3

    # Save data to the output params
    vertex_endpoint.uri = endpoint.resource_name # 4
    vertex_model.uri = deployed_model.resource_name 
```

- 1: ëª¨ë¸ì„ ì—…ë¡œë“œí•˜ëŠ” ê³¼ì •ì€ google cloudì˜ ì„œë¹„ìŠ¤ì— ì¢…ì†ì ì´ë‹¤.
- 2: ëª¨ë¸ ì„œë¹™ì„ ìœ„í•´ì„œ ì €ì¥í•œ ëª¨ë¸ì„ ë¶ˆëŸ¬ì™€ì„œ Vertex aiì—ì„œ ê´€ë¦¬í•˜ëŠ” ëª¨ë¸ë¡œ ë“±ë¡í•œë‹¤. ì´ë•Œ ì–´ë– í•œ ì´ë¯¸ì§€ë¥¼ ê¸°ë°˜ìœ¼ë¡œ serving ëª¨ë¸ì„ ë§Œë“¤ì§€ `serving_container_image_uri ` ë¡œ ì§€ì •í•´ì¤˜ì•¼ í•œë‹¤.  [ì—¬ê¸°](https://console.cloud.google.com/artifacts/docker/vertex-ai/us/prediction)ì— ë“¤ì–´ê°€ë©´ Predictionì„ ìœ„í•œ ë‹¤ì–‘í•œ ë² ì´ìŠ¤ ì´ë¯¸ì§€ë¥¼ í™•ì¸í•  ìˆ˜ ìˆë‹¤.
- 3: 2ì—ì„œ ì—…ë¡œë“œí•œ ëª¨ë¸ì„ endpointì™€ ì—°ê²°ì§“ëŠ” ë¶€ë¶„ì´ë‹¤. endpointë¥¼ ì¸ìë¡œ ì£¼ì§€ ì•Šìœ¼ë©´ disploy_nameì˜ ì´ë¦„ìœ¼ë¡œ ìë™ìœ¼ë¡œ ìƒì„±ëœë‹¤. ì—¬ê¸°ì„œ ë°°í¬ë¥¼ ìœ„í•œ replicas, accelartor ê·¸ë¦¬ê³  í•˜ë‚˜ì˜ ì—”ë“œí¬ì¸íŠ¸ì— ì—¬ëŸ¬ê°œì˜ ëª¨ë¸ì´ ì—°ê²°ë  ìˆ˜ ìˆìœ¼ë¯€ë¡œ traffic_percentage ë“±ë„ ì„¤ì •ì´ ê°€ëŠ¥í•˜ë‹¤. [ì—¬ê¸°](https://googleapis.dev/python/aiplatform/latest/aiplatform.html#google.cloud.aiplatform.Model.deploy)ë¥¼ ì°¸ê³ í•˜ì.
- 4: componentì˜ Outputìœ¼ë¡œ ì§€ì •í•œ `vertex_endpoint` , `vertex_model` ì´ ì²˜ìŒìœ¼ë¡œ ë“±ì¥í–ˆëŠ”ë°, ë‹¨ìˆœíˆ ì»´í¬ë„ŒíŠ¸ì˜ ê²°ê³¼ë¡œì„œ ë°°í¬ëœ ëª¨ë¸ì˜ ì •ë³´ì™€ Endpointì˜ ì •ë³´ë¥¼ í™•ì¸í•˜ê¸° ìœ„í•¨ì´ë‹¤. ì‚¬ì‹¤ ê¼­ í•„ìš”í•œ ë¶€ë¶„ì€ ì•„ë‹ˆë‹¤. 



4ë²ˆê³¼ ê°™ì´ Ouputì„ ì§€ì •í•´ì£¼ë©´ ì•„ë˜ì˜ ì‚¬ì§„ê³¼ ê°™ì´ Pipelineì—ì„œ ì •ë³´ë“¤ì„ ì¶œë ¥í•´ì¤€ë‹¤.

<img src="outputs.png" width="50%"/>

ê·¸ë¦¬ê³  ê° ì•„í‹°íŒ©íŠ¸ì˜ ì„¸ë¶€ì •ë³´ë¥¼ í™•ì¸í•´ë³´ë©´ urië¥¼ í™•ì¸í•  ìˆ˜ ìˆë‹¤.

<img src="artifacts.png" width="50%"/>

## 3. Define Pipeline

ìœ„ì—ì„œ ì •ì˜í•œ ë‘ê°œì˜ ì»´í¬ë„ŒíŠ¸ë¥¼ ì‹¤í–‰í•˜ëŠ” Pipelineì„ ì‘ì„±í•œë‹¤.

```python
@dsl.pipeline(
    pipeline_root=PIPELINE_ROOT, # 1
    name="simple-mnist-pipeline",
)
def pipeline(
    project: str = PROJECT_ID, # 2
    region: str = REGION
):
    load_data_and_training_task = load_data_and_training() # 3

    deploy_task = deploy_model( # 4
        model=load_data_and_training_task.outputs["output_model"],
        project=project,
        region=region
    )
```

- 1: íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•˜ë©´ì„œ ìƒì„±ë  Artifactsë¥¼ ì €ì¥í•˜ê¸° ìœ„í•œ ì¤‘ê°„ ì €ì¥ì†Œì´ë‹¤. MinIO, S3, GCS ë“±ì„ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤.
- 2: ì•ì„œ ì„¤ëª…í–ˆë‹¤ì‹œí”¼ `deploy_model` ì˜ ê²½ìš° google cloudì— ì¢…ì†ì ì´ë‹¤. íŒŒë¼ë¯¸í„°ë¡œ ê°’ì„ ë°›ì•„ deployë¥¼ ìœ„í•´ ì‚¬ìš©í•œë‹¤.
- 3: ì²˜ìŒìœ¼ë¡œ ì •ì˜í•œ Load data & Training Component ë¥¼ ì‹¤í–‰í•˜ëŠ” ë¶€ë¶„ì´ë‹¤.
- 4: ë‘ë²ˆì§¸ë¡œ ì •ì˜í•œ Deploy with endpoint ë¥¼ ì‹¤í–‰í•˜ëŠ” ë¶€ë¶„ì´ë‹¤. load_data_and_training_taskì˜ ouput ì¤‘ output_modelë¥¼ ë¶ˆëŸ¬ì™€ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©í•œë‹¤.



## 4. Run Pipeline

ì •ì˜í•œ íŒŒì´í”„ë¼ì¸ì„ Vertex AIì—ì„œ ì‹¤í–‰í•˜ëŠ” ë¶€ë¶„ì´ë‹¤.

```python
TIMESTAMP = datetime.now().strftime("%Y%m%d%H%M%S")

compiler.Compiler().compile(
    pipeline_func=pipeline, package_path="simple_mnist_pipeline.json"
)

run = pipeline_jobs.PipelineJob(
    display_name="simple-mnist-pipeline",
    template_path="simple_mnist_pipeline.json",
    job_id="simple-mnist-pipeline-{0}".format(TIMESTAMP),
    parameter_values={},
    enable_caching=True,
)

run.run(sync=False)
```

